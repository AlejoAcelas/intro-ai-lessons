{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction to Neural Networks\n",
                "\n",
                "Session content:\n",
                "* ML is about learning functions (15 min)\n",
                "* Gradient descent helps find the \"best\" function (1 min)\n",
                "* Neural networks (and their descendants) are very good function approximators (30 min)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ML is about learning functions (15 min)\n",
                "\n",
                "Think about Spotify's \"Recommended Songs\" feature. How does it know what songs you might like? At its core, it's using a function that:\n",
                "- Takes in: Your listening history, liked songs, and other user data\n",
                "- Gives out: A list of songs you might enjoy\n",
                "\n",
                "This is what machine learning is all about - creating functions that can learn from data to make predictions or decisions. Let's practice identifying these input/output patterns in different ML systems.\n",
                "\n",
                "For each example below:\n",
                "1. First, think about what information the system needs (inputs)\n",
                "2. Then, consider what the system should produce (outputs)\n",
                "3. Finally, try writing the function header yourself before checking the solution"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I'll do an example myself so that you can see what we're aiming for.\n",
                "\n",
                "**Sentiment Classifier**\n",
                "A movie theater wants to know whether the Instagram comments about their movies are positive or negative. The machine learning system they'll use will probably look like:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_sentiment(movie_comment: str) -> float:\n",
                "    \"\"\"\n",
                "    Input: A text message like \"I love this movie!\"\n",
                "    Output: A number from -1 (very negative) to 1 (very positive)\n",
                "    \"\"\"\n",
                "    pass # The 'pass' keyword indicates the function is not yet implemented"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Try a couple other examples yourself!\n",
                "\n",
                "**Image classifier**  \n",
                "A self-driving car company wants to know whether an image shows a pedestrian. Try writing in the code block below how you would write the function header for that machine learning system.\n",
                "\n",
                "<details>\n",
                "    <summary>One Possible Solution (Only look after trying yourself!!)</summary>\n",
                "    ```  \n",
                "    \n",
                "    import numpy as np\n",
                "\n",
                "    def is_pedestrian(image: np.ndarray) -> bool:\n",
                "        \"\"\"\n",
                "        Input: A numpy array representing an image. The shape of the array is (height, width, 3)\n",
                "        where the last dimension indicates the color in RGB with three numbers, each for red, green and blue.\n",
                "        Output: A boolean (True or False) indicating whether the image shows a pedestrian\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the header function for the image classifier here:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "An interesting question from the previous exercise is: how can we pass an image to an ML system in a way it understands? While we might think to use image files (like PNG or JPEG), to the system these are just collections of 1s and 0s that are hard to process directly.\n",
                "Under the hood, ML systems can only work with numbers. Whether we're dealing with text, images, or audio, there's always a process to convert the input into numbers that the system can understand (and sometimes convert those numbers back into a format we humans can interpret).\n",
                "For images, this conversion process is fairly straightforward. Think of an image as a grid of tiny squares called pixels. Each pixel is like a mixture of three colors - red, green, and blue - where we measure how much of each color we use (from 0 to 1). For example:\n",
                "\n",
                "(1, 0, 0) means \"full red, no green, no blue\" = Pure red\n",
                "(0, 1, 0) means \"no red, full green, no blue\" = Pure green\n",
                "(0.5, 0.5, 0.5) means \"half of each\" = Gray\n",
                "\n",
                "When we represent an image in this way, it becomes an array with three dimensions:\n",
                "\n",
                "height = number of rows in our grid\n",
                "width = number of columns\n",
                "3 = our red, green, blue measurements for each pixel\n",
                "\n",
                "Let's see how this works in practice. In the code below, you can change the values of red_values, blue_values, and green_values to see how different color combinations create different images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "red_values = [\n",
                "    [0.8, 0, 0],\n",
                "    [0, 0.7, 0],\n",
                "    [0, 0, 0.9]\n",
                "]\n",
                "blue_values = [\n",
                "    [0, 0, 0.6],\n",
                "    [0, 0.5, 0],\n",
                "    [0.7, 0, 0]\n",
                "]\n",
                "green_values = [\n",
                "    [0, 0.8, 1],\n",
                "    [0.6, 0, 0],\n",
                "    [0, 0, 0.5]\n",
                "]\n",
                "\n",
                "# Create image matrices of shape (height, width, [R, G, B])\n",
                "red_img = np.zeros((3, 3, 3))\n",
                "blue_img = np.zeros((3, 3, 3))\n",
                "green_img = np.zeros((3, 3, 3))\n",
                "\n",
                "# Set the values for each channel\n",
                "red_img[:, :, 0] = np.array(red_values)  # Red channel\n",
                "blue_img[:, :, 2] = np.array(blue_values)  # Blue channel\n",
                "green_img[:, :, 1] = np.array(green_values)  # Green channel\n",
                "combined_img = red_img + blue_img + green_img\n",
                "\n",
                "def plot_image_matrices(red_img, blue_img, green_img, combined_img):\n",
                "    # Create a figure with 4 subplots side by side\n",
                "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))\n",
                "\n",
                "    # Plot each image\n",
                "    ax1.imshow(red_img)\n",
                "    ax1.set_title('Red Values')\n",
                "    ax1.axis('off')\n",
                "\n",
                "    ax2.imshow(blue_img)\n",
                "    ax2.set_title('Blue Values') \n",
                "    ax2.axis('off')\n",
                "\n",
                "    ax3.imshow(green_img)\n",
                "    ax3.set_title('Green Values')\n",
                "    ax3.axis('off')\n",
                "\n",
                "    ax4.imshow(combined_img)\n",
                "    ax4.set_title('Combined Values')\n",
                "    ax4.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "plot_image_matrices(red_img, blue_img, green_img, combined_img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also see how the process looks for a real image from the internet. I lowered the resolution of the image so that it's more evident that it's composed of individual pixels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and display a sample image\n",
                "from PIL import Image\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Get a small sample image from the internet (an astronaut picture)\n",
                "url = \"https://raw.githubusercontent.com/scikit-image/scikit-image/master/skimage/data/astronaut.png\"\n",
                "response = requests.get(url)\n",
                "img = Image.open(BytesIO(response.content))\n",
                "\n",
                "def plot_image_by_channels(img):\n",
                "    # Resize to a very low resolution (e.g., 64x64)\n",
                "    small_img = img.resize((64, 64))\n",
                "\n",
                "    # Convert to numpy array\n",
                "    img_array = np.array(small_img)\n",
                "\n",
                "    # Create figure and display\n",
                "    plt.figure(figsize=(15, 4))\n",
                "\n",
                "    # Original image\n",
                "    plt.subplot(1, 5, 1)\n",
                "    plt.imshow(img)\n",
                "    plt.title('Original Image')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Resized image\n",
                "    plt.subplot(1, 5, 2)\n",
                "    plt.imshow(img_array)\n",
                "    plt.title('64x64 Resolution')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Red channel\n",
                "    plt.subplot(1, 5, 3)\n",
                "    plt.imshow(img_array[:,:,0], cmap='Reds')\n",
                "    plt.title('Red Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Green channel\n",
                "    plt.subplot(1, 5, 4)\n",
                "    plt.imshow(img_array[:,:,1], cmap='Greens')\n",
                "    plt.title('Green Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Blue channel\n",
                "    plt.subplot(1, 5, 5)\n",
                "    plt.imshow(img_array[:,:,2], cmap='Blues')\n",
                "    plt.title('Blue Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "    # Print the shape of the low-resolution image array\n",
                "    print(f\"Low resolution image shape: {img_array.shape}\")\n",
                "\n",
                "plot_image_by_channels(img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you're interested you can ask an AI how the process of encoding the input into numbers works for text, which would be needed to create ML systems like ChatGPT (e.g., \"How does ChatGPT encode text? I'm only slightly familiar with neural networks and machine learning\").\n",
                "\n",
                "For now, we'll ignore this process and assume ML systems can receive text directly. What would the header function look like for this ML system:\n",
                "\n",
                "**LLM Chatbot**\n",
                "OpenAI is creating a chatbot that can answer questions on chatgpt.com. To reduce costs, this chatbot does not accept images or voice, only text prompts. Similarly, it only outputs text.\n",
                "\n",
                "<details>\n",
                "    <summary>One Possible Solution</summary>\n",
                "    ```python\n",
                "    def chatbot(user_message: str) -> str:\n",
                "        \"\"\"\n",
                "        Input: A string with the user's message\n",
                "        Output: A string with the chatbot's response\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the header function for the chatbot here:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradient descent helps find the \"best\" function (1 min)\n",
                "\n",
                "Although the math and intuition behind gradient descent is incredibly cool, we don't have enough time to cover it here. If you're interested, I recommend this 3Blue1Brown video ([english](https://www.youtube.com/watch?v=IHZwWFHWa-w), [espa√±ol](https://www.youtube.com/watch?v=mwHiaTrQOiI)). Also, if you want to be challenged, you can try implementing the gradient descent algorithm by yourself at this [page](https://neetcode.io/problems/gradient-descent)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Neural Networks: The Ultimate Function Learners (30 min)\n",
                "\n",
                "Remember how we described machine learning as finding the right function for a task? To do this effectively, we need a flexible system that can be shaped into many different types of functions - like clay that can be molded into any shape. This is where neural networks shine.\n",
                "\n",
                "Neural networks have revolutionized machine learning because they're incredibly good at learning complex patterns. They have three key advantages:\n",
                "\n",
                "* **Expressive Power**: Neural networks are universal function approximators - a fancy way of saying that if you give them enough neurons and tune them correctly, they can represent practically any function you want. Think of it like having enough LEGO blocks to build anything you can imagine.\n",
                "\n",
                "* **Parallel Processing**: Training neural networks involves doing many similar calculations at once. Modern computers are very good at this kind of parallel processing, making neural networks both fast to train and cost-effective to use.\n",
                "\n",
                "* **Pattern Recognition**: Advanced neural networks (like the Transformers used in ChatGPT) are remarkably efficient at spotting patterns in data. While they need lots of training data, the amount required is actually achievable with today's technology.\n",
                "\n",
                "In this notebook, we'll focus on Multi-Layer Perceptrons (MLPs) - the simplest type of neural network. While MLPs might seem basic compared to the neural networks powering today's AI systems, they're perfect for learning the core concepts. Think of them as the \"Hello World\" of neural networks - once you understand MLPs, you'll have a strong foundation for understanding more advanced architectures like RNNs, CNNs, and Transformers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's experiment with different types of ML models to see how they perform on a classic problem: recognizing handwritten digits (MNIST dataset).\n",
                "\n",
                "You can adjust:\n",
                "- MLP Width: How many neurons are in each layer (more = more complex patterns)\n",
                "- MLP Depth: How many layers of neurons (more = deeper patterns)\n",
                "- Tree Depth: How detailed the decision tree's rules can be\n",
                "- Dataset Size: How many examples we use for training\n",
                "\n",
                "Try to answer:\n",
                "1. What happens when you increase the width vs. the depth?\n",
                "2. Does more training data always help?\n",
                "3. Which model seems to learn fastest with limited data?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_openml\n",
                "\n",
                "# Load MNIST dataset\n",
                "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
                "X = X / 255.0  # Scale pixel values\n",
                "\n",
                "# Plot some example MNIST digits\n",
                "plt.figure(figsize=(10, 2))\n",
                "for i in range(5):\n",
                "    plt.subplot(1, 5, i+1)\n",
                "    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
                "    plt.title(f'Label: {y[i]}')\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(X.shape, \"The images are 28x28 pixels, so 784 pixels once flattened.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import ipywidgets as widgets\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "\n",
                "def compare_predictions():\n",
                "    \"\"\"Compare predictions of different models on MNIST.\"\"\"\n",
                "    \n",
                "    # Create widgets for hyperparameters\n",
                "    mlp_width = widgets.IntSlider(value=32, min=4, max=64, description='MLP Width:')\n",
                "    mlp_depth = widgets.IntSlider(value=2, min=1, max=8, description='MLP Depth:')\n",
                "    tree_depth = widgets.IntSlider(value=5, min=1, max=20, description='Tree Depth:')\n",
                "    train_size = widgets.IntSlider(value=1_000, min=100, max=5_000, description='Dataset Size:')\n",
                "    # Create placeholder for output\n",
                "    output = widgets.HTML()\n",
                "        \n",
                "    val_size = 2_000    \n",
                "    \n",
                "    def train_and_plot(mlp_width, mlp_depth, tree_depth, train_size):\n",
                "        \n",
                "        output.value = \"Training models...\"\n",
                "        \n",
                "        X_train, y_train = X[:train_size], y[:train_size]\n",
                "        X_val, y_val = X[-val_size:], y[-val_size:]\n",
                "\n",
                "        # Train logistic regression once\n",
                "        lr_model = LogisticRegression(max_iter=1000)\n",
                "        lr_model.fit(X_train, y_train)\n",
                "        lr_acc = lr_model.score(X_val, y_val)\n",
                "        \n",
                "        # Train decision tree\n",
                "        dt_model = DecisionTreeClassifier(max_depth=tree_depth)\n",
                "        dt_model.fit(X_train, y_train)\n",
                "        dt_acc = dt_model.score(X_val, y_val)\n",
                "        \n",
                "        # Train MLP\n",
                "        mlp_model = MLPClassifier(\n",
                "            hidden_layer_sizes=(mlp_width,)*mlp_depth,\n",
                "            activation='relu',\n",
                "            max_iter=1000\n",
                "        )\n",
                "        mlp_model.fit(X_train, y_train)\n",
                "        mlp_acc = mlp_model.score(X_val, y_val)\n",
                "    \n",
                "        output.value = (f\"MLP Accuracy: {mlp_acc:.2f}<br>\"\n",
                "                        f\"Logistic Regression Accuracy: {lr_acc:.2f}<br>\"\n",
                "                        f\"Decision Tree Accuracy: {dt_acc:.2f}\")\n",
                "    \n",
                "    controls = {'mlp_width': mlp_width, 'mlp_depth': mlp_depth, 'tree_depth': tree_depth, 'train_size': train_size}\n",
                "    widgets.interact(train_and_plot, **controls, continuous_update=False)\n",
                "    display(output)\n",
                "\n",
                "compare_predictions()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Looking at our results, something interesting emerges: the logistic regression performs surprisingly well, often matching or even outperforming the MLP on the MNIST dataset. While both these methods significantly outperform the decision tree, the MLP's advantage isn't as dramatic as we might expect. (Don't worry though - for more complex problems beyond MNIST, MLPs typically show much greater benefits.)\n",
                "\n",
                "However, this strong performance comes with a trade-off: MLPs are much harder to interpret than simpler models. With logistic regression or decision trees, we can easily visualize and understand how they make decisions. In contrast, when we try to visualize an MLP's internal workings, we get something that looks like this:\n",
                "\n",
                "![MLP weights visualization](https://i.sstatic.net/Z5L70.png)\n",
                "\n",
                "In this visualization, each circle represents a neuron that can be activated by different inputs, and the lines show how earlier neurons influence later ones through weighted connections. While pretty, this complexity makes it hard to understand exactly how the network makes its decisions.\n",
                "\n",
                "To better understand how neural networks work, let's zoom in and experiment with a much simpler version. Here's an interesting way to think about it: computers can perform complex tasks like sending emails, playing videos, or running Python code by combining very simple operations (like AND and OR) many times. Similarly, if we can show that neural networks can perform these basic operations, we can understand how they might be combined to tackle more complex tasks.\n",
                "\n",
                "Let's try this hands-on by building the simplest possible neural network: one with just two inputs (each either 0 or 1) and a single neuron for output. Your challenge is to make this tiny network perform basic logical operations:\n",
                "\n",
                "- For AND: The output should be ON only when both inputs are ON\n",
                "- For OR: The output should be ON when either input (or both) is ON\n",
                "\n",
                "You can adjust the network's behavior using:\n",
                "- Weights (shown as lines): Blue = positive influence, Red = negative influence\n",
                "- Bias: An additional value that makes it easier or harder for the neuron to activate\n",
                "- The darkness of the neuron shows how strongly it's activated\n",
                "\n",
                "Try different combinations and see if you can make the network properly implement these logical operations!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Create widgets for weight adjustment\n",
                "target_function = widgets.Dropdown(options=['AND', 'OR'], description='Target Function:')\n",
                "w1_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Weight 1:')\n",
                "w2_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Weight 2:') \n",
                "bias_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Bias:')\n",
                "first_input_on = widgets.Checkbox(value=False, description='First input ON')\n",
                "second_input_on = widgets.Checkbox(value=False, description='Second input ON')\n",
                "\n",
                "\n",
                "def plot_neuron(target_function, w1, w2, bias, first_input_on, second_input_on):\n",
                "    plt.clf()\n",
                "    \n",
                "    relu = lambda x: max(0, x)\n",
                "    \n",
                "    first_input_coords = (0, 1)\n",
                "    second_input_coords = (1, 1)\n",
                "    neuron_coords = (0.5, 0.5)\n",
                "    \n",
                "    # Plot inputs\n",
                "    x1 = 1 if first_input_on else 0\n",
                "    x2 = 1 if second_input_on else 0\n",
                "    \n",
                "    # Calculate actual and expected values\n",
                "    actual = relu(w1*x1 + w2*x2 + bias)\n",
                "    expected = x1 and x2 if target_function == 'AND' else x1 or x2  # AND gate\n",
                "    \n",
                "    # Plot input points with fill based on input state\n",
                "    plt.plot(first_input_coords[0], first_input_coords[1], 'ko', markersize=10,\n",
                "             fillstyle='full' if first_input_on else 'none')\n",
                "    plt.plot(second_input_coords[0], second_input_coords[1], 'ko', markersize=10,\n",
                "             fillstyle='full' if second_input_on else 'none')\n",
                "    \n",
                "    # Plot neuron with activation-based color\n",
                "    fill_color = f\"{1 - np.clip(actual, 0, 1):.2f}\"\n",
                "    plt.plot(neuron_coords[0], neuron_coords[1], 'ko', markersize=20,\n",
                "             fillstyle='full', markerfacecolor=fill_color)\n",
                "    \n",
                "    # Plot connections with weight-based colors\n",
                "\n",
                "    plt.plot(*zip(first_input_coords, neuron_coords), \n",
                "            color='blue' if w1 > 0 else 'red',\n",
                "            alpha=abs(w1/2),\n",
                "            linewidth=2)\n",
                "    plt.plot(*zip(second_input_coords, neuron_coords),\n",
                "            color='blue' if w2 > 0 else 'red',\n",
                "            alpha=abs(w2/2),\n",
                "            linewidth=2)\n",
                "    \n",
                "    # Remove grid and spines\n",
                "    plt.gca().axis('off')\n",
                "    plt.xlim(-0.5, 1.5)\n",
                "    plt.ylim(-0.5, 1.5)\n",
                "    \n",
                "    # Print values\n",
                "    is_on = lambda x: \"ON\" if x > 0 else \"OFF\"\n",
                "    plt.text(-0.4, -0.4, f'Expected: {is_on(expected)}\\nActual: {is_on(actual)}')\n",
                "    print('The plots appear twice, sorry!')\n",
                "    plt.show()\n",
                "    \n",
                "# Display interactive widgets\n",
                "widgets.interactive(\n",
                "    plot_neuron, \n",
                "    target_function=target_function,\n",
                "    w1=w1_slider,\n",
                "    w2=w2_slider,\n",
                "    bias=bias_slider,\n",
                "    first_input_on=first_input_on,\n",
                "    second_input_on=second_input_on,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we've seen how neural networks can learn basic logical operations like AND and OR, let's zoom out and consider how these same principles can tackle much more complex challenges - like teaching a computer to have human-like conversations.\n",
                "\n",
                "Imagine we have a dataset of written conversations and want to teach an ML model to participate in them naturally. We might think to use an MLP like the ones we've explored, but we'd quickly encounter several challenges:\n",
                "\n",
                "* Overfitting: Just as our simple network needed the right balance of weights to learn AND/OR operations, a conversation model needs to learn genuine patterns of human communication rather than just memorizing specific examples.\n",
                "* Model size: Remember how our digit recognition improved with larger networks? For something as complex as human language, we'd need a dramatically larger network - think millions or billions of neurons instead of dozens.\n",
                "* Computational cost: Training such a massive network on enough conversation data to make it useful would require enormous computing power - thousands of specialized chips (GPUs) running for months.\n",
                "\n",
                "This was exactly the challenge OpenAI tackled. They started small, with GPT-1: a relatively simple neural network trained on a modest collection of books (you can try it [here](https://huggingface.co/spaces/mkmenta/try-gpt-1-and-gpt-2)). While this first attempt produced rather clumsy text, it proved something important: neural networks could begin to grasp human language patterns.\n",
                "\n",
                "The truly remarkable discovery was that scaling up this approach - using bigger networks, more data, and more computing power - led to systems that could engage in surprisingly human-like conversation. Just as our simple networks learned to combine basic operations into more complex behaviors, these larger networks learned to combine basic language patterns into meaningful dialogue.\n",
                "\n",
                "However, getting to this point required moving beyond the MLP architecture we've explored today. In our next session, we'll dive into Transformers - the specialized neural network architecture that powers modern AI language models like GPT-4, Claude, and Llama 3. We'll see how they build upon the fundamental concepts we've learned while introducing clever innovations that make them particularly well-suited for processing language."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
