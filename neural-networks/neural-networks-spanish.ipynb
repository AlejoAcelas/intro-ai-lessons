{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introducción a las Redes Neuronales\n",
                "\n",
                "Contenido de la sesión:\n",
                "* El ML trata sobre el aprendizaje de funciones (15 min)\n",
                "* El descenso del gradiente ayuda a encontrar la \"mejor\" función (1 min)\n",
                "* Las redes neuronales (y sus descendientes) son muy buenos aproximadores de funciones (30 min)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## El ML trata sobre el aprendizaje de funciones (15 min)\n",
                "\n",
                "Piensa en la función \"Canciones Recomendadas\" de Spotify. ¿Cómo sabe qué canciones te podrían gustar? En su esencia, está utilizando una función que:\n",
                "- Recibe: Tu historial de reproducción, canciones que te gustan y otros datos de usuario\n",
                "- Produce: Una lista de canciones que podrían gustarte\n",
                "\n",
                "De esto trata el machine learning - crear funciones que pueden aprender de los datos para hacer predicciones o tomar decisiones. Practiquemos identificando estos patrones de entrada/salida en diferentes sistemas de ML.\n",
                "\n",
                "Para cada ejemplo a continuación:\n",
                "1. Primero, piensa en qué información necesita el sistema (entradas)\n",
                "2. Luego, considera qué debe producir el sistema (salidas)\n",
                "3. Finalmente, intenta escribir el encabezado de la función por ti mismo antes de revisar la solución\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Haré un ejemplo yo mismo para que puedas ver lo que buscamos.\n",
                "\n",
                "**Clasificador de Sentimientos**\n",
                "Un cine quiere saber si los comentarios de Instagram sobre sus películas son positivos o negativos. El sistema de machine learning que utilizarán probablemente se verá así:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clasificar_sentimiento(comentario_pelicula: str) -> float:\n",
                "    \"\"\"\n",
                "    Entrada: Un mensaje de texto como \"¡Me encanta esta película!\"\n",
                "    Salida: Un número desde -1 (muy negativo) hasta 1 (muy positivo)\n",
                "    \"\"\"\n",
                "    pass # La palabra clave 'pass' indica que la función aún no está implementada\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "¡Intenta un par de ejemplos tú mismo!\n",
                "\n",
                "**Clasificador de imágenes**  \n",
                "Una empresa de vehículos autónomos quiere saber si una imagen muestra a un peatón. Intenta escribir en el bloque de código siguiente cómo escribirías el encabezado de la función para ese sistema de machine learning.\n",
                "\n",
                "<details>\n",
                "    <summary>Una Posible Solución (¡¡Mira solo después de intentarlo tú mismo!!)</summary>\n",
                "    ```  \n",
                "    \n",
                "    import numpy as np\n",
                "\n",
                "    def es_peaton(imagen: np.ndarray) -> bool:\n",
                "        \"\"\"\n",
                "        Entrada: Un array numpy que representa una imagen. La forma del array es (altura, ancho, 3)\n",
                "        donde la última dimensión indica el color en RGB con tres números, cada uno para rojo, verde y azul.\n",
                "        Salida: Un booleano (True o False) que indica si la imagen muestra un peatón\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crea aquí el encabezado de la función para el clasificador de imágenes:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una pregunta interesante del ejercicio anterior es: ¿cómo podemos pasar una imagen a un sistema de ML de manera que la entienda? Aunque podríamos pensar en usar archivos de imagen (como PNG o JPEG), para el sistema estos son solo colecciones de 1s y 0s que son difíciles de procesar directamente.\n",
                "\n",
                "En el fondo, los sistemas de ML solo pueden trabajar con números. Ya sea que estemos tratando con texto, imágenes o audio, siempre hay un proceso para convertir la entrada en números que el sistema pueda entender (y a veces convertir esos números de vuelta a un formato que los humanos podamos interpretar).\n",
                "\n",
                "Para las imágenes, este proceso de conversión es bastante directo. Piensa en una imagen como una cuadrícula de pequeños cuadrados llamados píxeles. Cada píxel es como una mezcla de tres colores - rojo, verde y azul - donde medimos cuánto de cada color usamos (de 0 a 1). Por ejemplo:\n",
                "\n",
                "(1, 0, 0) significa \"rojo completo, sin verde, sin azul\" = Rojo puro\n",
                "(0, 1, 0) significa \"sin rojo, verde completo, sin azul\" = Verde puro\n",
                "(0.5, 0.5, 0.5) significa \"mitad de cada uno\" = Gris\n",
                "\n",
                "Cuando representamos una imagen de esta manera, se convierte en un array con tres dimensiones:\n",
                "\n",
                "altura = número de filas en nuestra cuadrícula\n",
                "ancho = número de columnas\n",
                "3 = nuestras mediciones de rojo, verde y azul para cada píxel\n",
                "\n",
                "Veamos cómo funciona esto en la práctica. En el código siguiente, puedes cambiar los valores de red_values, blue_values y green_values para ver cómo diferentes combinaciones de colores crean diferentes imágenes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "valores_rojo = [\n",
                "    [0.8, 0, 0],\n",
                "    [0, 0.7, 0],\n",
                "    [0, 0, 0.9]\n",
                "]\n",
                "valores_azul = [\n",
                "    [0, 0, 0.6],\n",
                "    [0, 0.5, 0],\n",
                "    [0.7, 0, 0]\n",
                "]\n",
                "valores_verde = [\n",
                "    [0, 0.8, 1],\n",
                "    [0.6, 0, 0],\n",
                "    [0, 0, 0.5]\n",
                "]\n",
                "\n",
                "# Crear matrices de imagen con forma (altura, ancho, [R, G, B])\n",
                "img_roja = np.zeros((3, 3, 3))\n",
                "img_azul = np.zeros((3, 3, 3))\n",
                "img_verde = np.zeros((3, 3, 3))\n",
                "\n",
                "# Establecer los valores para cada canal\n",
                "img_roja[:, :, 0] = np.array(valores_rojo)  # Canal rojo\n",
                "img_azul[:, :, 2] = np.array(valores_azul)  # Canal azul\n",
                "img_verde[:, :, 1] = np.array(valores_verde)  # Canal verde\n",
                "img_combinada = img_roja + img_azul + img_verde\n",
                "\n",
                "def graficar_matrices_imagen(img_roja, img_azul, img_verde, img_combinada):\n",
                "    # Crear una figura con 4 subgráficos lado a lado\n",
                "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))\n",
                "\n",
                "    # Graficar cada imagen\n",
                "    ax1.imshow(img_roja)\n",
                "    ax1.set_title('Valores Rojos')\n",
                "    ax1.axis('off')\n",
                "\n",
                "    ax2.imshow(img_azul)\n",
                "    ax2.set_title('Valores Azules')\n",
                "    ax2.axis('off')\n",
                "\n",
                "    ax3.imshow(img_verde)\n",
                "    ax3.set_title('Valores Verdes')\n",
                "    ax3.axis('off')\n",
                "\n",
                "    ax4.imshow(img_combinada)\n",
                "    ax4.set_title('Valores Combinados')\n",
                "    ax4.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "graficar_matrices_imagen(img_roja, img_azul, img_verde, img_combinada)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "También podemos ver cómo funciona el proceso con una imagen real de internet. Reduje la resolución de la imagen para que sea más evidente que está compuesta por píxeles individuales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cargar y mostrar una imagen de ejemplo\n",
                "from PIL import Image\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Obtener una pequeña imagen de ejemplo de internet (una foto de astronauta)\n",
                "url = \"https://raw.githubusercontent.com/scikit-image/scikit-image/master/skimage/data/astronaut.png\"\n",
                "respuesta = requests.get(url)\n",
                "img = Image.open(BytesIO(respuesta.content))\n",
                "\n",
                "def graficar_imagen_por_canales(img):\n",
                "    # Redimensionar a una resolución muy baja (ej., 64x64)\n",
                "    imagen_pequeña = img.resize((64, 64))\n",
                "\n",
                "    # Convertir a array de numpy\n",
                "    array_imagen = np.array(imagen_pequeña)\n",
                "\n",
                "    # Crear figura y mostrar\n",
                "    plt.figure(figsize=(15, 4))\n",
                "\n",
                "    # Imagen original\n",
                "    plt.subplot(1, 5, 1)\n",
                "    plt.imshow(img)\n",
                "    plt.title('Imagen Original')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Imagen redimensionada\n",
                "    plt.subplot(1, 5, 2)\n",
                "    plt.imshow(array_imagen)\n",
                "    plt.title('Resolución 64x64')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Canal rojo\n",
                "    plt.subplot(1, 5, 3)\n",
                "    plt.imshow(array_imagen[:,:,0], cmap='Reds')\n",
                "    plt.title('Canal Rojo')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Canal verde\n",
                "    plt.subplot(1, 5, 4)\n",
                "    plt.imshow(array_imagen[:,:,1], cmap='Greens')\n",
                "    plt.title('Canal Verde')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Canal azul\n",
                "    plt.subplot(1, 5, 5)\n",
                "    plt.imshow(array_imagen[:,:,2], cmap='Blues')\n",
                "    plt.title('Canal Azul')\n",
                "    plt.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "    # Imprimir la forma del array de la imagen de baja resolución\n",
                "    print(f\"Forma de la imagen de baja resolución: {array_imagen.shape}\")\n",
                "\n",
                "graficar_imagen_por_canales(img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Si estás interesado, puedes preguntarle a una IA cómo funciona el proceso de codificación de texto a números, que sería necesario para crear sistemas de ML como ChatGPT (por ejemplo, \"¿Cómo codifica el texto ChatGPT? Solo estoy ligeramente familiarizado con redes neuronales y machine learning\").\n",
                "\n",
                "Por ahora, ignoraremos este proceso y asumiremos que los sistemas de ML pueden recibir texto directamente. ¿Cómo se vería el encabezado de la función para este sistema de ML?:\n",
                "\n",
                "**Chatbot LLM**\n",
                "OpenAI está creando un chatbot que puede responder preguntas en chatgpt.com. Para reducir costos, este chatbot no acepta imágenes ni voz, solo texto. De manera similar, solo produce texto como salida.\n",
                "\n",
                "<details>\n",
                "    <summary>Una Posible Solución</summary>\n",
                "    ```python\n",
                "    def chatbot(mensaje_usuario: str) -> str:\n",
                "        \"\"\"\n",
                "        Entrada: Una cadena con el mensaje del usuario\n",
                "        Salida: Una cadena con la respuesta del chatbot\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear el encabezado de función para el chatbot aquí:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## El descenso del gradiente ayuda a encontrar la \"mejor\" función (1 min)\n",
                "\n",
                "Aunque las matemáticas y la intuición detrás del descenso del gradiente son increíblemente interesantes, no tenemos suficiente tiempo para cubrirlo aquí. Si estás interesado, recomiendo este video de 3Blue1Brown ([inglés](https://www.youtube.com/watch?v=IHZwWFHWa-w), [español](https://www.youtube.com/watch?v=mwHiaTrQOiI)). Además, si quieres un reto, puedes intentar implementar el algoritmo de descenso del gradiente por ti mismo en esta [página](https://neetcode.io/problems/gradient-descent).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Redes Neuronales: Los Mejores Aprendices de Funciones (30 min)\n",
                "\n",
                "¿Recuerdas cómo describimos el machine learning como la búsqueda de la función correcta para una tarea? Para hacer esto de manera efectiva, necesitamos un sistema flexible que pueda moldearse en muchos tipos diferentes de funciones - como arcilla que puede moldearse en cualquier forma. Aquí es donde brillan las redes neuronales.\n",
                "\n",
                "Las redes neuronales han revolucionado el machine learning porque son increíblemente buenas aprendiendo patrones complejos. Tienen tres ventajas clave:\n",
                "\n",
                "* **Poder Expresivo**: Las redes neuronales son aproximadores universales de funciones - una manera elegante de decir que si les das suficientes neuronas y las ajustas correctamente, pueden representar prácticamente cualquier función que desees. Piensa en ello como tener suficientes bloques de LEGO para construir cualquier cosa que puedas imaginar.\n",
                "\n",
                "* **Procesamiento Paralelo**: El entrenamiento de redes neuronales implica hacer muchos cálculos similares a la vez. Las computadoras modernas son muy buenas en este tipo de procesamiento paralelo, haciendo que las redes neuronales sean rápidas de entrenar y rentables de usar.\n",
                "\n",
                "* **Reconocimiento de Patrones**: Las redes neuronales avanzadas (como los Transformers utilizados en ChatGPT) son notablemente eficientes para detectar patrones en los datos. Si bien necesitan muchos datos de entrenamiento, la cantidad requerida es realmente alcanzable con la tecnología actual.\n",
                "\n",
                "En este notebook, nos centraremos en los Perceptrones Multicapa (MLPs) - el tipo más simple de red neuronal. Aunque los MLPs puedan parecer básicos en comparación con las redes neuronales que impulsan los sistemas de IA actuales, son perfectos para aprender los conceptos fundamentales. Piensa en ellos como el \"Hola Mundo\" de las redes neuronales - una vez que entiendas los MLPs, tendrás una base sólida para comprender arquitecturas más avanzadas como RNNs, CNNs y Transformers.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos a experimentar con diferentes tipos de modelos de ML para ver cómo se comportan en un problema clásico: reconocer dígitos escritos a mano (conjunto de datos MNIST).\n",
                "\n",
                "Puedes ajustar:\n",
                "- Ancho del MLP: Cuántas neuronas hay en cada capa (más = patrones más complejos)\n",
                "- Profundidad del MLP: Cuántas capas de neuronas (más = patrones más profundos)\n",
                "- Profundidad del Árbol: Qué tan detalladas pueden ser las reglas del árbol de decisión\n",
                "- Tamaño del Conjunto de Datos: Cuántos ejemplos usamos para el entrenamiento\n",
                "\n",
                "Intenta responder:\n",
                "1. ¿Qué sucede cuando aumentas el ancho vs. la profundidad?\n",
                "2. ¿Más datos de entrenamiento siempre ayudan?\n",
                "3. ¿Qué modelo parece aprender más rápido con datos limitados?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_openml\n",
                "\n",
                "# Cargar conjunto de datos MNIST\n",
                "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
                "X = X / 255.0  # Escalar valores de píxeles\n",
                "\n",
                "# Graficar algunos dígitos MNIST de ejemplo\n",
                "plt.figure(figsize=(10, 2))\n",
                "for i in range(5):\n",
                "    plt.subplot(1, 5, i+1)\n",
                "    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
                "    plt.title(f'Etiqueta: {y[i]}')\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(X.shape, \"Las imágenes son de 28x28 píxeles, así que 784 píxeles una vez aplanadas.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import ipywidgets as widgets\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "\n",
                "def comparar_predicciones():\n",
                "    \"\"\"Compara predicciones de diferentes modelos en MNIST.\"\"\"\n",
                "    \n",
                "    # Crear widgets para hiperparámetros\n",
                "    ancho_mlp = widgets.IntSlider(value=32, min=4, max=64, description='Ancho MLP:')\n",
                "    profundidad_mlp = widgets.IntSlider(value=2, min=1, max=8, description='Profundidad MLP:')\n",
                "    profundidad_arbol = widgets.IntSlider(value=5, min=1, max=20, description='Profundidad Árbol:')\n",
                "    tamanio_entrenamiento = widgets.IntSlider(value=1_000, min=100, max=5_000, description='Tamaño Datos:')\n",
                "    # Crear espacio para salida\n",
                "    salida = widgets.HTML()\n",
                "        \n",
                "    tamanio_validacion = 2_000    \n",
                "    \n",
                "    def entrenar_y_graficar(ancho_mlp, profundidad_mlp, profundidad_arbol, tamanio_entrenamiento):\n",
                "        \n",
                "        salida.value = \"Entrenando modelos...\"\n",
                "        \n",
                "        X_entren, y_entren = X[:tamanio_entrenamiento], y[:tamanio_entrenamiento]\n",
                "        X_val, y_val = X[-tamanio_validacion:], y[-tamanio_validacion:]\n",
                "\n",
                "        # Entrenar regresión logística una vez\n",
                "        modelo_rl = LogisticRegression(max_iter=1000)\n",
                "        modelo_rl.fit(X_entren, y_entren)\n",
                "        precision_rl = modelo_rl.score(X_val, y_val)\n",
                "        \n",
                "        # Entrenar árbol de decisión\n",
                "        modelo_ad = DecisionTreeClassifier(max_depth=profundidad_arbol)\n",
                "        modelo_ad.fit(X_entren, y_entren)\n",
                "        precision_ad = modelo_ad.score(X_val, y_val)\n",
                "        \n",
                "        # Entrenar MLP\n",
                "        modelo_mlp = MLPClassifier(\n",
                "            hidden_layer_sizes=(ancho_mlp,)*profundidad_mlp,\n",
                "            activation='relu',\n",
                "            max_iter=1000\n",
                "        )\n",
                "        modelo_mlp.fit(X_entren, y_entren)\n",
                "        precision_mlp = modelo_mlp.score(X_val, y_val)\n",
                "    \n",
                "        salida.value = (f\"Precisión MLP: {precision_mlp:.2f}<br>\"\n",
                "                       f\"Precisión Regresión Logística: {precision_rl:.2f}<br>\"\n",
                "                       f\"Precisión Árbol de Decisión: {precision_ad:.2f}\")\n",
                "    \n",
                "    controles = {'ancho_mlp': ancho_mlp, 'profundidad_mlp': profundidad_mlp, \n",
                "                 'profundidad_arbol': profundidad_arbol, 'tamanio_entrenamiento': tamanio_entrenamiento}\n",
                "    widgets.interact(entrenar_y_graficar, **controles, continuous_update=False)\n",
                "    display(salida)\n",
                "\n",
                "comparar_predicciones()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Observando nuestros resultados, surge algo interesante: la regresión logística tiene un rendimiento sorprendentemente bueno, a menudo igualando o incluso superando al MLP en el conjunto de datos MNIST. Si bien ambos métodos superan significativamente al árbol de decisión, la ventaja del MLP no es tan dramática como podríamos esperar. (No te preocupes - para problemas más complejos más allá de MNIST, los MLPs típicamente muestran beneficios mucho mayores.)\n",
                "\n",
                "Sin embargo, este alto rendimiento viene con un compromiso: los MLPs son mucho más difíciles de interpretar que los modelos más simples. Con la regresión logística o los árboles de decisión, podemos visualizar y entender fácilmente cómo toman decisiones. En contraste, cuando intentamos visualizar el funcionamiento interno de un MLP, obtenemos algo que se ve así:\n",
                "\n",
                "![Visualización de pesos MLP](https://i.sstatic.net/Z5L70.png)\n",
                "\n",
                "En esta visualización, cada círculo representa una neurona que puede ser activada por diferentes entradas, y las líneas muestran cómo las neuronas anteriores influyen en las posteriores a través de conexiones ponderadas. Aunque es bonito, esta complejidad hace que sea difícil entender exactamente cómo la red toma sus decisiones.\n",
                "\n",
                "Para entender mejor cómo funcionan las redes neuronales, vamos a hacer zoom y experimentar con una versión mucho más simple. Aquí hay una forma interesante de pensarlo: las computadoras pueden realizar tareas complejas como enviar correos electrónicos, reproducir videos o ejecutar código Python combinando operaciones muy simples (como AND y OR) muchas veces. De manera similar, si podemos mostrar que las redes neuronales pueden realizar estas operaciones básicas, podemos entender cómo podrían combinarse para abordar tareas más complejas.\n",
                "\n",
                "Probemos esto de manera práctica construyendo la red neuronal más simple posible: una con solo dos entradas (cada una 0 o 1) y una única neurona para la salida. Tu desafío es hacer que esta pequeña red realice operaciones lógicas básicas:\n",
                "\n",
                "- Para AND: La salida debe estar ACTIVA solo cuando ambas entradas están ACTIVAS\n",
                "- Para OR: La salida debe estar ACTIVA cuando cualquiera de las entradas (o ambas) está ACTIVA\n",
                "\n",
                "Puedes ajustar el comportamiento de la red usando:\n",
                "- Pesos (mostrados como líneas): Azul = influencia positiva, Rojo = influencia negativa\n",
                "- Sesgo (bias): Un valor adicional que hace más fácil o más difícil que la neurona se active\n",
                "- La oscuridad de la neurona muestra qué tan fuertemente está activada\n",
                "\n",
                "¡Prueba diferentes combinaciones y ve si puedes hacer que la red implemente correctamente estas operaciones lógicas!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Crear widgets para ajuste de pesos\n",
                "funcion_objetivo = widgets.Dropdown(options=['AND', 'OR'], description='Función Objetivo:')\n",
                "peso1_deslizador = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Peso 1:')\n",
                "peso2_deslizador = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Peso 2:') \n",
                "sesgo_deslizador = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Sesgo:')\n",
                "primera_entrada_activa = widgets.Checkbox(value=False, description='Primera entrada ACTIVA')\n",
                "segunda_entrada_activa = widgets.Checkbox(value=False, description='Segunda entrada ACTIVA')\n",
                "\n",
                "\n",
                "def graficar_neurona(funcion_objetivo, p1, p2, sesgo, primera_entrada_activa, segunda_entrada_activa):\n",
                "    plt.clf()\n",
                "    \n",
                "    relu = lambda x: max(0, x)\n",
                "    \n",
                "    coords_primera_entrada = (0, 1)\n",
                "    coords_segunda_entrada = (1, 1)\n",
                "    coords_neurona = (0.5, 0.5)\n",
                "    \n",
                "    # Graficar entradas\n",
                "    x1 = 1 if primera_entrada_activa else 0\n",
                "    x2 = 1 if segunda_entrada_activa else 0\n",
                "    \n",
                "    # Calcular valores reales y esperados\n",
                "    real = relu(p1*x1 + p2*x2 + sesgo)\n",
                "    esperado = x1 and x2 if funcion_objetivo == 'AND' else x1 or x2  # Compuerta AND\n",
                "    \n",
                "    # Graficar puntos de entrada con relleno basado en estado de entrada\n",
                "    plt.plot(coords_primera_entrada[0], coords_primera_entrada[1], 'ko', markersize=10,\n",
                "             fillstyle='full' if primera_entrada_activa else 'none')\n",
                "    plt.plot(coords_segunda_entrada[0], coords_segunda_entrada[1], 'ko', markersize=10,\n",
                "             fillstyle='full' if segunda_entrada_activa else 'none')\n",
                "    \n",
                "    # Graficar neurona con color basado en activación\n",
                "    color_relleno = f\"{1 - np.clip(real, 0, 1):.2f}\"\n",
                "    plt.plot(coords_neurona[0], coords_neurona[1], 'ko', markersize=20,\n",
                "             fillstyle='full', markerfacecolor=color_relleno)\n",
                "    \n",
                "    # Graficar conexiones con colores basados en peso\n",
                "    plt.plot(*zip(coords_primera_entrada, coords_neurona), \n",
                "            color='blue' if p1 > 0 else 'red',\n",
                "            alpha=abs(p1/2),\n",
                "            linewidth=2)\n",
                "    plt.plot(*zip(coords_segunda_entrada, coords_neurona),\n",
                "            color='blue' if p2 > 0 else 'red',\n",
                "            alpha=abs(p2/2),\n",
                "            linewidth=2)\n",
                "    \n",
                "    # Eliminar cuadrícula y bordes\n",
                "    plt.gca().axis('off')\n",
                "    plt.xlim(-0.5, 1.5)\n",
                "    plt.ylim(-0.5, 1.5)\n",
                "    \n",
                "    # Imprimir valores\n",
                "    esta_activo = lambda x: \"ACTIVO\" if x > 0 else \"INACTIVO\"\n",
                "    plt.text(-0.4, -0.4, f'Esperado: {esta_activo(esperado)}\\nReal: {esta_activo(real)}')\n",
                "    print('Los gráficos aparecen dos veces, ¡lo siento!')\n",
                "    plt.show()\n",
                "    \n",
                "# Mostrar widgets interactivos\n",
                "widgets.interactive(\n",
                "    graficar_neurona, \n",
                "    funcion_objetivo=funcion_objetivo,\n",
                "    p1=peso1_deslizador,\n",
                "    p2=peso2_deslizador,\n",
                "    sesgo=sesgo_deslizador,\n",
                "    primera_entrada_activa=primera_entrada_activa,\n",
                "    segunda_entrada_activa=segunda_entrada_activa,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora que hemos visto cómo las redes neuronales pueden aprender operaciones lógicas básicas como AND y OR, alejémonos un poco y consideremos cómo estos mismos principios pueden abordar desafíos mucho más complejos - como enseñar a una computadora a mantener conversaciones similares a las humanas.\n",
                "\n",
                "Imagina que tenemos un conjunto de datos de conversaciones escritas y queremos enseñar a un modelo de ML a participar en ellas de manera natural. Podríamos pensar en usar un MLP como los que hemos explorado, pero rápidamente encontraríamos varios desafíos:\n",
                "\n",
                "* Sobreajuste: Así como nuestra red simple necesitaba el balance correcto de pesos para aprender operaciones AND/OR, un modelo de conversación necesita aprender patrones genuinos de comunicación humana en lugar de solo memorizar ejemplos específicos.\n",
                "* Tamaño del modelo: ¿Recuerdas cómo nuestro reconocimiento de dígitos mejoró con redes más grandes? Para algo tan complejo como el lenguaje humano, necesitaríamos una red dramáticamente más grande - piensa en millones o billones de neuronas en lugar de docenas.\n",
                "* Costo computacional: Entrenar una red tan masiva con suficientes datos de conversación para hacerla útil requeriría un poder de cómputo enorme - miles de chips especializados (GPUs) funcionando durante meses.\n",
                "\n",
                "Este fue exactamente el desafío que abordó OpenAI. Comenzaron pequeño, con GPT-1: una red neuronal relativamente simple entrenada en una modesta colección de libros (puedes probarlo [aquí](https://huggingface.co/spaces/mkmenta/try-gpt-1-and-gpt-2)). Si bien este primer intento produjo texto bastante torpe, probó algo importante: las redes neuronales podían comenzar a comprender patrones del lenguaje humano.\n",
                "\n",
                "El descubrimiento verdaderamente notable fue que escalar este enfoque - usando redes más grandes, más datos y más poder de cómputo - llevó a sistemas que podían participar en conversaciones sorprendentemente similares a las humanas. Así como nuestras redes simples aprendieron a combinar operaciones básicas en comportamientos más complejos, estas redes más grandes aprendieron a combinar patrones básicos de lenguaje en diálogos significativos.\n",
                "\n",
                "Sin embargo, llegar a este punto requirió ir más allá de la arquitectura MLP que hemos explorado hoy. En nuestra próxima sesión, profundizaremos en los Transformers - la arquitectura especializada de red neuronal que impulsa los modelos modernos de lenguaje de IA como GPT-4, Claude y Llama 3. Veremos cómo se basan en los conceptos fundamentales que hemos aprendido mientras introducen innovaciones inteligentes que los hacen particularmente adecuados para procesar lenguaje.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
