{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction to Neural Networks\n",
                "Lesson Plan:\n",
                "* ML is about learning functions\n",
                "* Gradient descent helps find the \"best\" function\n",
                "* Neural networks (and their descendants) are very good function approximators"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ML is about learning functions (15 min)\n",
                "\n",
                "To get an intuition  for how current machine learning systems work, we'll pick a couple real-world ML systems and try to express them as functions.\n",
                "\n",
                "For each example below:\n",
                "1. Think about what information the function needs (inputs)\n",
                "2. Think about what the function should return (outputs)\n",
                "3. Try writing the function header yourself before checking the solution"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I'll do an example myself so that you can see what we're aiming for.\n",
                "\n",
                "**Sentiment Classifier**\n",
                "A movie theater wants to know whether the Instagram comments about their movies are positive or negative. The machine learning system they'll use will probably look like:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_sentiment(movie_comment: str) -> float:\n",
                "    \"\"\"\n",
                "    Input: A text message like \"I love this movie!\"\n",
                "    Output: A number from -1 (very negative) to 1 (very positive)\n",
                "    \"\"\"\n",
                "    pass # The 'pass' keyword indicates the function is not yet implemented"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Try a couple other examples yourself!\n",
                "\n",
                "**Image classifier**  \n",
                "A self-driving car company wants to know whether an image shows a pedestrian. Try writing in the code block below how you would write the function header for that machine learning system.\n",
                "\n",
                "<details>\n",
                "    <summary>One Possible Solution (Only look after trying yourself!!)</summary>\n",
                "    ```  \n",
                "    \n",
                "    import numpy as np\n",
                "\n",
                "    def is_pedestrian(image: np.ndarray) -> bool:\n",
                "        \"\"\"\n",
                "        Input: A numpy array representing an image. The shape of the array is (height, width, 3)\n",
                "        where the last dimension indicates the color in RGB with three numbers, each for red, green and blue.\n",
                "        Output: A boolean (True or False) indicating whether the image shows a pedestrian\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the header function for the image classifier here:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "An interesting question for the previous exercise is, how can we pass the image to the ML system in a way it understands it? We could think of passing an image file (e.g., PNG or JPEG), but to the system that is only a large collection of 1s and 0s and it's really hard to make sense of it. \n",
                "\n",
                "Below the hood, ML systems can only understand their inputs and outputs if they are numbers. When we pass a piece of text, an image, or an audio, there's a process underneath to convert them into numbers, and also for converting them back into some format we can understand.\n",
                "\n",
                "For images this process is fairly straightforward. We just take every pixel and extract the intensity (from 0 to 1) of three base colors: red, green, and blue. Then we represent the image as a collection of all the pixel values arranged as an array of shape (height, width, 3).\n",
                "\n",
                "Let's see an example of how this works. You can change the values of `red_values`, `blue_values`, and `green_values` to see how the image changes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "red_values = [\n",
                "    [0.8, 0, 0],\n",
                "    [0, 0.7, 0],\n",
                "    [0, 0, 0.9]\n",
                "]\n",
                "blue_values = [\n",
                "    [0, 0, 0.6],\n",
                "    [0, 0.5, 0],\n",
                "    [0.7, 0, 0]\n",
                "]\n",
                "green_values = [\n",
                "    [0, 0.8, 1],\n",
                "    [0.6, 0, 0],\n",
                "    [0, 0, 0.5]\n",
                "]\n",
                "\n",
                "# Create image matrices of shape (height, width, [R, G, B])\n",
                "red_img = np.zeros((3, 3, 3))\n",
                "blue_img = np.zeros((3, 3, 3))\n",
                "green_img = np.zeros((3, 3, 3))\n",
                "\n",
                "# Set the values for each channel\n",
                "red_img[:, :, 0] = np.array(red_values)  # Red channel\n",
                "blue_img[:, :, 2] = np.array(blue_values)  # Blue channel\n",
                "green_img[:, :, 1] = np.array(green_values)  # Green channel\n",
                "combined_img = red_img + blue_img + green_img\n",
                "\n",
                "def plot_image_matrices(red_img, blue_img, green_img, combined_img):\n",
                "    # Create a figure with 4 subplots side by side\n",
                "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))\n",
                "\n",
                "    # Plot each image\n",
                "    ax1.imshow(red_img)\n",
                "    ax1.set_title('Red Values')\n",
                "    ax1.axis('off')\n",
                "\n",
                "    ax2.imshow(blue_img)\n",
                "    ax2.set_title('Blue Values') \n",
                "    ax2.axis('off')\n",
                "\n",
                "    ax3.imshow(green_img)\n",
                "    ax3.set_title('Green Values')\n",
                "    ax3.axis('off')\n",
                "\n",
                "    ax4.imshow(combined_img)\n",
                "    ax4.set_title('Combined Values')\n",
                "    ax4.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "plot_image_matrices(red_img, blue_img, green_img, combined_img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also see how the process looks for a real image from the internet. I lowered the resolution of the image so that it's more evident that it's composed of individual pixels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and display a sample image\n",
                "from PIL import Image\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Get a small sample image from the internet (an astronaut picture)\n",
                "url = \"https://raw.githubusercontent.com/scikit-image/scikit-image/master/skimage/data/astronaut.png\"\n",
                "response = requests.get(url)\n",
                "img = Image.open(BytesIO(response.content))\n",
                "\n",
                "def plot_image_by_channels(img):\n",
                "    # Resize to a very low resolution (e.g., 64x64)\n",
                "    small_img = img.resize((64, 64))\n",
                "\n",
                "    # Convert to numpy array\n",
                "    img_array = np.array(small_img)\n",
                "\n",
                "    # Create figure and display\n",
                "    plt.figure(figsize=(15, 4))\n",
                "\n",
                "    # Original image\n",
                "    plt.subplot(1, 5, 1)\n",
                "    plt.imshow(img)\n",
                "    plt.title('Original Image')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Resized image\n",
                "    plt.subplot(1, 5, 2)\n",
                "    plt.imshow(img_array)\n",
                "    plt.title('64x64 Resolution')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Red channel\n",
                "    plt.subplot(1, 5, 3)\n",
                "    plt.imshow(img_array[:,:,0], cmap='Reds')\n",
                "    plt.title('Red Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Green channel\n",
                "    plt.subplot(1, 5, 4)\n",
                "    plt.imshow(img_array[:,:,1], cmap='Greens')\n",
                "    plt.title('Green Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    # Blue channel\n",
                "    plt.subplot(1, 5, 5)\n",
                "    plt.imshow(img_array[:,:,2], cmap='Blues')\n",
                "    plt.title('Blue Channel')\n",
                "    plt.axis('off')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "    # Print the shape of the low-resolution image array\n",
                "    print(f\"Low resolution image shape: {img_array.shape}\")\n",
                "\n",
                "plot_image_by_channels(img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you're interested you can ask an AI how the process of encoding the input into numbers works for text, which would be needed to create ML systems like ChatGPT (e.g., \"How does ChatGPT encode text? I'm only slightly familiar with neural networks and machine learning\").\n",
                "\n",
                "For now, we'll ignore this process and assume ML systems can receive text directly. What would the header function look like for this ML system:\n",
                "\n",
                "**LLM Chatbot**\n",
                "OpenAI is creating a chatbot that can answer questions on chatgpt.com. To reduce costs, this chatbot does not accept images or voice, only text prompts. Similarly, it only outputs text.\n",
                "\n",
                "<details>\n",
                "    <summary>One Possible Solution</summary>\n",
                "    ```python\n",
                "    def chatbot(user_message: str) -> str:\n",
                "        \"\"\"\n",
                "        Input: A string with the user's message\n",
                "        Output: A string with the chatbot's response\n",
                "        \"\"\"\n",
                "        pass\n",
                "    ```    \n",
                "</details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the header function for the chatbot here:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradient descent helps find the \"best\" function (1 min)\n",
                "\n",
                "Although the math and intuition behind gradient descent is incredibly cool, we don't have enough time to cover it here. If you're interested, I recommend this 3Blue1Brown video ([english](https://www.youtube.com/watch?v=IHZwWFHWa-w), [español](https://www.youtube.com/watch?v=mwHiaTrQOiI)). Also, if you want to be challenged, you can try implementing the gradient descent algorithm by yourself at this [page](https://neetcode.io/problems/gradient-descent)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Neural networks are very good function approximators (30 min)\n",
                "\n",
                "To ensure gradient descent finds a function that solves the task, we need to have a good substrate, in the form of a model architecture  that can be tuned to take the form of many different functions. Neural networks (and their descendants) have shown to be remarkably good at learning functions, partly for these reasons:\n",
                "* Expressive power: You can prove that after stacking enough neurons and tuning the parameters, you can form practically any function.\n",
                "* Paralellism: Training NNs consists of carrying out many identical operations, which can be computed in parallel at the same time, massively speeding up the process and reducing costs.\n",
                "* Efficiency: Some NN variants (like Transformers, the architecture used by ChatGPT) can learn extremely sophisticated patterns from amounts of data that, while large, are still attainable from current sources.\n",
                "\n",
                "In this notebook we'll focus on multi-layer perceptrons (MLPs), which are the simplest type of neural networks. While they are rarely used directly in practical applications, many of the lessons we can derive from playing with them are directly applicable to more complex architectures (such as RNNs, CNNs, and Transformers)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To start with, let's try to get an intuition for just how expressive neural networks can be. In this excercise we'll take a twisted function and see how different machine learning systems do at approximating it.\n",
                "\n",
                "You can play with the depth and width of the MLP to see how it changes its ability to approximate the underlying function.\n",
                "\n",
                "We'll use PyTorch to create the data and train the models. You can think of PyTorch as a version of Numpy that is optimized for machine learning applications. PyTorch is also structured around the creation of arrays (now called tensors), but includes additional functions, and modules that are useful to train machine learning models. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "def spiral(phi):\n",
                "    x = (phi + 1) * torch.cos(phi)\n",
                "    y = phi * torch.sin(phi)\n",
                "    return torch.cat((x, y), dim=1)\n",
                "\n",
                "\n",
                "def generate_data(num_data):\n",
                "    angles = torch.empty((num_data, 1)).uniform_(1, 15)\n",
                "    data = spiral(angles)\n",
                "    # Add some noise to the data.\n",
                "    data += torch.empty((num_data, 2)).normal_(0.0, 0.4)\n",
                "    labels = torch.zeros((num_data,), dtype=torch.int)\n",
                "    # Flip half of the points to create two classes.\n",
                "    data[num_data // 2 :, :] *= -1\n",
                "    labels[num_data // 2 :] = 1\n",
                "    return data, labels\n",
                "\n",
                "x_train, y_train = generate_data(4000)\n",
                "x_val, y_val = generate_data(1000)\n",
                "\n",
                "print(\"x_train shape:\", x_train.size())\n",
                "print(\"y_train shape:\", y_train.size())\n",
                "\n",
                "\n",
                "def plot_data(x, y):\n",
                "    \"\"\"Plot data points x with labels y. Label 1 is a red +, label 0 is a blue +.\"\"\"\n",
                "    plt.figure(figsize=(5, 5))\n",
                "    plt.plot(x[y == 1, 0], x[y == 1, 1], \"r+\")\n",
                "    plt.plot(x[y == 0, 0], x[y == 0, 1], \"b+\")\n",
                "    \n",
                "    \n",
                "plot_data(x_train, y_train)\n",
                "\n",
                "import ipywidgets as widgets\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "\n",
                "def create_mlp(width, depth):\n",
                "    layers = []\n",
                "    layers.append(nn.Linear(2, width))\n",
                "    layers.append(nn.ReLU())\n",
                "    \n",
                "    for _ in range(depth-1):\n",
                "        layers.append(nn.Linear(width, width))\n",
                "        layers.append(nn.ReLU())\n",
                "        \n",
                "    layers.append(nn.Linear(width, 1))\n",
                "    layers.append(nn.Sigmoid())\n",
                "    \n",
                "    return nn.Sequential(*layers)\n",
                "\n",
                "def train_mlp(model, x, y, epochs=100):\n",
                "    optimizer = optim.Adam(model.parameters())\n",
                "    criterion = nn.BCELoss()\n",
                "    \n",
                "    for _ in range(epochs):\n",
                "        optimizer.zero_grad()\n",
                "        output = model(x)\n",
                "        loss = criterion(output.squeeze(), y.float())\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "def compare_predictions(x=x_val, y=y_val):\n",
                "    \"\"\"Compare predictions of different models.\"\"\"\n",
                "    \n",
                "    # Train logistic regression\n",
                "    lr_model = LogisticRegression()\n",
                "    lr_model.fit(x_train, y_train)\n",
                "    lr_pred = lr_model.predict(x)\n",
                "    lr_acc = (lr_pred == y.numpy()).mean()\n",
                "    \n",
                "    # Train decision tree\n",
                "    dt_model = DecisionTreeClassifier()\n",
                "    dt_model.fit(x_train, y_train)\n",
                "    dt_pred = dt_model.predict(x)\n",
                "    dt_acc = (dt_pred == y.numpy()).mean()\n",
                "    \n",
                "    # Create and train MLP with widget controls\n",
                "    width_slider = widgets.IntSlider(value=32, min=4, max=128, description='Width:')\n",
                "    depth_slider = widgets.IntSlider(value=2, min=1, max=5, description='Depth:')\n",
                "    \n",
                "    @widgets.interact(width=width_slider, depth=depth_slider)\n",
                "    def train_and_plot(width, depth):\n",
                "        mlp_model = create_mlp(width, depth)\n",
                "        train_mlp(mlp_model, x_train, y_train)\n",
                "        \n",
                "        with torch.inference_mode():\n",
                "            mlp_pred = (mlp_model(x).squeeze() > 0.5).float()\n",
                "        mlp_acc = (mlp_pred == y).float().mean()\n",
                "\n",
                "        plt.figure(figsize=(15, 5))\n",
                "\n",
                "        # Plot logistic regression\n",
                "        plt.subplot(131)\n",
                "        reds = lr_pred > 0.5\n",
                "        plt.plot(x[reds, 0], x[reds, 1], \"r+\")\n",
                "        plt.plot(x[~reds, 0], x[~reds, 1], \"b+\")\n",
                "        plt.title(f\"Logistic Regression\\nAccuracy: {lr_acc:.3f}\")\n",
                "\n",
                "        # Plot decision tree\n",
                "        plt.subplot(132)\n",
                "        reds = dt_pred > 0.5\n",
                "        plt.plot(x[reds, 0], x[reds, 1], \"r+\")\n",
                "        plt.plot(x[~reds, 0], x[~reds, 1], \"b+\")\n",
                "        plt.title(f\"Decision Tree\\nAccuracy: {dt_acc:.3f}\")\n",
                "\n",
                "        # Plot MLP\n",
                "        plt.subplot(133)\n",
                "        reds = mlp_pred > 0.5\n",
                "        plt.plot(x[reds, 0], x[reds, 1], \"r+\")\n",
                "        plt.plot(x[~reds, 0], x[~reds, 1], \"b+\")\n",
                "        plt.title(f\"MLP (w={width}, d={depth})\\nAccuracy: {mlp_acc:.3f}\")\n",
                "\n",
                "        plt.tight_layout()\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Although the MLP does much better at this task, it does so partly at the cost of being less interpretable. We can easily visualize the algorithm behind a logistic regression or a decision tree, but if you were to plot the weights of an MLP, it would look somewhat like this:\n",
                "\n",
                "![MLP weights visualization](https://i.sstatic.net/Z5L70.png)\n",
                "\n",
                "The circles represent neurons that can be active or not for a given input, while the lines represent the weights that determine how early neurons influence the later ones to form the output.\n",
                "\n",
                "Although the network we trained is too big to quickly get an intuitive grasp of how it works, we can learn a few things by playing with a smaller version of an MLP.\n",
                "\n",
                "As an illustration, we know that computers can send emails, reproduce videos, run Python code, and many other things by repeating many times some basic operations (such as taking the AND and OR of two bits). If neural networks can also implement these basic operations, in theory they can be piled up to perform anything a computer can do (in reality, we).\n",
                "\n",
                "Let's then try to manually set the weights for an MLP to implement the AND and OR operations.\n",
                "\n",
                "The following neural network receives two inputs which are either 0 or 1. It has depth 1, so its output is just the value taken by its only neuron."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "70d613457674419b815a0c3b2adf6d05",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "interactive(children=(FloatSlider(value=0.0, description='Weight 1:', max=2.0, min=-2.0), FloatSlider(value=0.…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Try to set the weights to implement an AND gate!\n",
                        "Hint: Both inputs should need to be ON (1) to activate the neuron.\n"
                    ]
                }
            ],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Create widgets for weight adjustment\n",
                "w1_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Weight 1:')\n",
                "w2_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Weight 2:') \n",
                "bias_slider = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.1, description='Bias:')\n",
                "\n",
                "def plot_neuron(w1, w2, bias):\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    \n",
                "    # Define sigmoid function\n",
                "    sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
                "    \n",
                "    # Plot inputs (0,0), (0,1), (1,0), (1,1)\n",
                "    inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
                "    for x1, x2 in inputs:\n",
                "        # Calculate neuron activation\n",
                "        activation = sigmoid(w1*x1 + w2*x2 + bias)\n",
                "        \n",
                "        # Plot input points\n",
                "        plt.plot(x1, x2, 'ko', markersize=10)\n",
                "        \n",
                "        # Plot neuron with activation-based color\n",
                "        plt.plot(0.5, 0.5, 'o', color=f'{1-float(activation):.2f}', \n",
                "                markersize=20, zorder=3)\n",
                "        \n",
                "        # Plot connections with weight-based colors\n",
                "        if x1 == 1:\n",
                "            plt.plot([1, 0.5], [x2, 0.5], \n",
                "                    color='red' if w1 > 0 else 'blue',\n",
                "                    alpha=abs(w1/2),\n",
                "                    linewidth=2)\n",
                "        if x2 == 1:\n",
                "            plt.plot([x1, 0.5], [1, 0.5],\n",
                "                    color='red' if w2 > 0 else 'blue',\n",
                "                    alpha=abs(w2/2),\n",
                "                    linewidth=2)\n",
                "    \n",
                "    # Calculate accuracy for AND operation\n",
                "    correct = 0\n",
                "    for x1, x2 in inputs:\n",
                "        pred = sigmoid(w1*x1 + w2*x2 + bias) > 0.5\n",
                "        target = x1 and x2\n",
                "        correct += int(pred == target)\n",
                "    accuracy = correct / len(inputs)\n",
                "    \n",
                "    plt.title(f'Neural Network AND Gate\\nAccuracy: {accuracy:.2f}')\n",
                "    plt.xlim(-0.5, 1.5)\n",
                "    plt.ylim(-0.5, 1.5)\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "\n",
                "def update_plot(w1, w2, bias):\n",
                "    plot_neuron(w1, w2, bias)\n",
                "\n",
                "# Display interactive widgets\n",
                "out = widgets.interactive(update_plot, \n",
                "                        w1=w1_slider,\n",
                "                        w2=w2_slider,\n",
                "                        bias=bias_slider)\n",
                "display(out)\n",
                "\n",
                "print(\"Try to set the weights to implement an AND gate!\")\n",
                "print(\"Hint: Both inputs should need to be ON (1) to activate the neuron.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Do the same for the OR gate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
